# AlphaZero on a Connect 4 environment

A deep reinforcement learning algorithm that plays Connect 4, based on AlphaZero. I'm creating this because [my chess algorithm](https://github.com/zjeffer/chess-deep-rl-cpp) learns too slowly, and I wanted to know if the problem is the amount of data needed, or my implementation of the algorithm itself.

## TODO

* [X] Connect 4 environment
* [X] MCTS algorithm
* [X] Neural network
* [ ] AlphaZero self-play
* [ ] Save played moves to memory, and memory to file
* [ ] AlphaZero training
* [ ] AlphaZero evaluation
* [ ] Play against computer
* [ ] GUI?
